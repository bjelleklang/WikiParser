{"ts":1361189669854,"silentsave":true,"restoring":false,"patch":[[{"diffs":[[1,"'''\nCreated on Feb 7, 2013\n\n@author: chris\n'''\n\nfrom xml.etree.cElementTree import iterparse\nfrom DataLogger import DataLogger\nimport string\nimport re\nimport pprint\nimport traceback\nimport pdb\nimport yaml\n\nclass XmlWrapper(object):\n    '''\n    Parses the xml-dump from Wikipedia. \n    iterparses the root element and only checks start events until a <page> is \n    found. Once we have a <page>, we also check the end event, in order to \n    analyze a specific article. \n    '''\n    xmldata = \"\"\n    context = \"\"\n    \n    def __init__(self, filename):\n        '''\n        Constructor\n        '''\n        self.context = iterparse( filename, events=(\"start\", \"end\"))\n        self.context = iter(self.context)\n    \n    def search(self):\n        '''\n            Iterates through a loop node looking for page nodes\n        '''\n        try:\n            stats = LogStats()\n            \n            event, root = self.context.next()\n                        \n            for event, element in self.context:\n                ns, tag = string.split(element.tag, '}', 1)\n    \n                # Parse node only if it's a page\n                if event == \"end\" and tag == \"page\":\n                    stats.parsePage(element)\n            \n                    root.clear()\n\n\n            # Cleanup, logging stats\n            stats.log()\n        except:\n            traceback.print_exc()\n            \n        return True\n        \n \nclass LogStats(object):\n    ''' Misc counters and numLists for keeping track of everything '''\n    pwithref = 0\n    pworef = 0\n    \n    nscounts = {}\n    articlestats = []\n    titlechecks = []\n    \n    lengthTotal = 0\n    numLinksTotal = 0\n    numExtLinksTotal = 0\n    numImgsTotal = 0\n    numTemplatesTotal = 0\n    numRedirects = 0\n    numLists = 0\n    numComparisons = 0\n    \n    \n    def __init__(self):\n       # Ignorelists. Any article matching these regexes should be ignored\n       # We don't need stats on these, as they are essentially a bunch of links\n       self.titlechecks.append('^List\\ ')\n       self.titlechecks.append('^Comparison\\ ')\n       self.titlechecks.append('^(January|February|March|April|March|April|May|June|July|August|September|October|November|December)($|\\ [0-9]{1,2}$)')\n       self.titlechecks.append('^[0-9]{1,10}($|\\ \\(number\\)$)') \n            \n    def parsePage(self, page):\n        ''' Takes a page and does something to it. Is only called if the \n            page isn't a redirect, list, number, month, date or similar. ''\n            ''' \n        \n        ns, tag = string.split(page.tag, '}', 1)\n        \n        # Ugly fix to include the namespace when searching for childnode. \n        # There just has to be a better way... \n        title = page.find(ns + \"}title\")\n        revision = page.find(ns + \"}revision\")\n        textNode = revision.find(ns + \"}text\")\n        \n        \n        validArticle = True\n        \n        # Log numRedirects, parse page if it isn't one\n        if self.isRedirect(textNode) == True:\n            self.numRedirects = self.numRedirects + 1 \n            validArticle = False\n        \n        if self.isListLike(title.text) == True:\n            self.numLists = self.numLists + 1\n            validArticle = False\n        \n        if validArticle == True:\n            articleNamespace = page.find(ns + \"}ns\").text\n            self.incrNs(articleNamespace) # Only logs valid articles \n            \n            if articleNamespace == \"0\":\n                # Parsing starts if we have an actual article. Ignore WP, Files, etc\n                p = PageData(page)\n                \n                self.articlestats.append(p)\n                self.lengthTotal = self.lengthTotal + p.length\n                self.numLinksTotal = self.numLinksTotal + p.numlinks \n                self.numExtLinksTotal = self.numExtLinksTotal + p.numextlinks \n                self.numImgsTotal = self.numImgsTotal + p.imagecount \n                self.numTemplatesTotal = self.numTemplatesTotal + p.numtemplates\n          \n    def incrNs(self, ns):\n        ''' Increments the ns register, registers ns if not already done '''\n        if ns not in self.nscounts:\n            self.nscounts[ns] = 0\n            \n        self.nscounts[ns] = self.nscounts[ns] + 1\n            \n    \n    \n    def isListLike(self, title):\n        '''\n            Checks the page title and compares it against the \n            regexes in titlechecks \n        '''\n        #matched = re.match(self.titlechecks, title)\n        combined = \"(\" + \")|(\".join(self.titlechecks) + \")\"\n        \n        if re.match(combined, title) == None:\n            return False\n        \n        return True\n    \n    def isRedirect(self, aTextElem):\n        '''\n            Checks if a page contains a redirect\n        '''\n        try:\n            aText = aTextElem.text\n            aText = aText.strip().lower()\n            status = \"\";\n            \n            if aText.startswith(\"#redirect\") == False:\n               return False\n            \n        except AttributeError:\n            return True\n        \n        return True\n    \n    def log(self):\n        DataLogger.l(\"/tmp/wplog.txt\", \"Num numRedirects: \" + str(self.numRedirects))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Num numLists: \" + str(self.numLists))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Num pages per ns: \" + pprint.pformat(self.nscounts))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Avg length: \" + pprint.pformat(self.lengthTotal / len(self.articlestats)))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Avg images per article: \" + pprint.pformat(self.numImgsTotal / len(self.articlestats)))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Avg extlinks: \" + pprint.pformat(self.numExtLinksTotal / len(self.articlestats)))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Avg wplinks: \" + pprint.pformat(self.numLinksTotal / len(self.articlestats)))\n        DataLogger.l(\"/tmp/wplog.txt\", \"Avg templates: \" + pprint.pformat(self.numTemplatesTotal / len(self.articlestats)))\n        \nclass PageData(object):\n    length = 0\n    numlinks = 0\n    numtemplates = 0\n    numextlinks = 0\n    imagecount = 0\n        \n    def __init__(self, page):\n        ''' \n            Simple constructor that looks for a ref and logs some stats about \n            this article. We ignore revisions for now, and only work with the \n            current rev. Later on, this should receive a number of revisions and \n            parse each of them, only checking for refs on the current rev. \n            \n            We also assume that no numRedirects are passed into this constructor, \n            as the stats we are logging would be useless for those.  \n        '''\n        \n        ns, tag = string.split(page.tag, '}', 1)\n        \n        title = page.find(ns + \"}title\")\n        revision = page.find(ns + \"}revision\")\n        textNode = revision.find(ns + \"}text\")\n        \n        # Parses the text and logs the article if it's missing a reftag\n        t = textNode.text\n        hasRef = self.hasRefTag(t)\n        \n        self.length = len(t)\n        self.numlinks = len(re.findall('\\[\\[', t))\n        self.numtemplates = len(re.findall('\\{\\{', t))\n        \n        # Regex for extlinks should be fixed and look for any single [ \n        # not preceded by another where alphanums follows.\n        self.numextlinks = len(re.findall('\\[\\ ?(http|https|www)', t))\n        self.imagecount = len(re.findall(r'\\[\\[(File|Image)\\:', t))\n        \n        if hasRef == False:\n            DataLogger.l(\"/tmp/wperror.txt\", \"Missing: [[\" + title.text + \"]]\")\n        \n        \n    def hasRefTag(self, aText):\n        '''\n            Receives the text of an article, lowercases everything and looks for \n            reftags\n        '''\n        try:\n            aText = aText.strip().lower()\n            status = \"\";\n            if aText.find(\"<ref\") == -1:\n                return False\n                \n        except AttributeError:\n            return True\n        \n        return True\n    \n    \n    \n"]],"start1":0,"start2":0,"length1":0,"length2":7920}]],"length":7920}
{"contributors":[],"silentsave":true,"ts":1361190004676,"patch":[[{"diffs":[[0,"n True\n    \n"],[1,"    def hasRefTag(self, aText):\n        '''\n            Receives the text of an article, lowercases everything and looks for \n            reftags\n        '''\n        try:\n            aText = aText.strip().lower()\n            status = \"\";\n            if aText.find(\"<ref\") == -1:\n                return False\n                \n        except AttributeError:\n            return True\n        \n        return True\n"],[0,"    \n    \n"]],"start1":7898,"start2":7898,"length1":22,"length2":431}]],"length":8329,"saved":false}
{"ts":1361190009539,"patch":[[{"diffs":[[0,"\n    def hasRefT"],[-1,"ag"],[0,"(self, aText):\n "]],"start1":7909,"start2":7909,"length1":34,"length2":32}]],"length":8327,"saved":false}
{"ts":1361190010196,"patch":[[{"diffs":[[0," hasRefT"],[1,"empl"],[0,"(self, a"]],"start1":7917,"start2":7917,"length1":16,"length2":20}]],"length":8331,"saved":false}
{"ts":1361190011417,"patch":[[{"diffs":[[0,"RefTempl"],[1,"ate"],[0,"(self, a"]],"start1":7921,"start2":7921,"length1":16,"length2":19}]],"length":8334,"saved":false}
{"ts":1361190021822,"patch":[[{"diffs":[[0,"\n            ref"],[-1,"tags"],[1,"erence t"],[0,"\n        '''\n   "]],"start1":8040,"start2":8040,"length1":36,"length2":40}]],"length":8338,"saved":false}
{"ts":1361190023888,"patch":[[{"diffs":[[0,"erence t"],[1,"emplates. "],[0,"\n       "]],"start1":8056,"start2":8056,"length1":16,"length2":26}]],"length":8348,"saved":false}
{"ts":1361190109256,"patch":[[{"diffs":[[0," if aText.find(\""],[-1,"<ref\""],[0,") == -1:\n       "]],"start1":8178,"start2":8178,"length1":37,"length2":32}]],"length":8343,"saved":false}
{"ts":1361190110378,"patch":[[{"diffs":[[0,"t.find(\""],[1,"\""],[0,") == -1:"]],"start1":8186,"start2":8186,"length1":16,"length2":17}]],"length":8344,"saved":false}
{"ts":1361190111861,"patch":[[{"diffs":[[0,"t.find(\""],[1,"{{"],[0,"\") == -1"]],"start1":8186,"start2":8186,"length1":16,"length2":18}]],"length":8346,"saved":false}
{"ts":1361190112982,"patch":[[{"diffs":[[0,"find(\"{{"],[1,"Template:Unreferenced"],[0,"\") == -1"]],"start1":8188,"start2":8188,"length1":16,"length2":37}]],"length":8367,"saved":false}
{"ts":1361190115772,"patch":[[{"diffs":[[0,"(\"{{"],[-1,"Template:"],[0,"Unre"]],"start1":8192,"start2":8192,"length1":17,"length2":8}]],"length":8358,"saved":false}
{"ts":1361190132407,"patch":[[{"diffs":[[0,"r()\n"],[-1,"            status = \"\";\n"],[0,"    "]],"start1":8138,"start2":8138,"length1":33,"length2":8}]],"length":8333,"saved":false}
{"ts":1361190136435,"patch":[[{"diffs":[[0,"r()\n"],[-1,"            status = \"\";"],[0,"\n   "]],"start1":7705,"start2":7705,"length1":32,"length2":8}]],"length":8309,"saved":false}
{"ts":1361190202669,"patch":[[{"diffs":[[0,"a reftag"],[1," or template"],[0,"\n       "]],"start1":6868,"start2":6868,"length1":16,"length2":28},{"diffs":[[0,"asRefTag(t)\n"],[1,"        hasRefTemplate = self.hasRefTemplate(t)\n"],[0,"        \n   "]],"start1":6938,"start2":6938,"length1":24,"length2":72},{"diffs":[[0,"asRef == False:\n"],[1,"            if hasRefTemplate == False:\n"],[0,"            Data"]],"start1":7442,"start2":7442,"length1":32,"length2":72},{"diffs":[[0,"lower()\n"],[-1,"\n"],[0,"        "]],"start1":7801,"start2":7801,"length1":17,"length2":16}]],"length":8408,"saved":false}
{"ts":1361190204328,"patch":[[{"diffs":[[0,"se:\n            "],[1,"    "],[0,"DataLogger.l(\"/t"]],"start1":7494,"start2":7494,"length1":32,"length2":36}]],"length":8412,"saved":false}
{"ts":1361190210617,"patch":[[{"diffs":[[0,"p/wp"],[-1,"error"],[1,"missing"],[0,".txt"]],"start1":7531,"start2":7531,"length1":13,"length2":15}]],"length":8414,"saved":false}
{"ts":1361190213871,"patch":[[{"diffs":[[0,"\"/tmp/wp"],[1,"_"],[0,"mi"],[-1,"ssing"],[0,".txt\", \""]],"start1":7527,"start2":7527,"length1":23,"length2":19}]],"length":8410,"saved":false}
{"ts":1361190217063,"patch":[[{"diffs":[[0,"mp/wp_mi"],[1,"ssing_ref"],[0,".txt\", \""]],"start1":7530,"start2":7530,"length1":16,"length2":25}]],"length":8419,"saved":false}
{"ts":1361190218273,"patch":[[{"diffs":[[0,"sing_ref"],[1,"_"],[0,".txt\", \""]],"start1":7539,"start2":7539,"length1":16,"length2":17}]],"length":8420,"saved":false}
{"ts":1361190219512,"patch":[[{"diffs":[[0,"ing_ref_"],[1,"tpl"],[0,".txt\", \""]],"start1":7540,"start2":7540,"length1":16,"length2":19}]],"length":8423,"saved":false}
{"ts":1361190222617,"patch":[[{"diffs":[[0,"+ \"]]\")\n"],[1,"            else \n"],[0,"        "]],"start1":7585,"start2":7585,"length1":16,"length2":34}]],"length":8441,"saved":false}
{"ts":1361190223354,"patch":[[{"diffs":[[0,"  else \n"],[1,"            \n"],[0,"        "]],"start1":7603,"start2":7603,"length1":16,"length2":29}]],"length":8454,"saved":false}
{"ts":1361190226153,"patch":[[{"diffs":[[0,"    else"],[1,":\n               "],[0," \n      "]],"start1":7601,"start2":7601,"length1":16,"length2":33}]],"length":8471,"saved":false}
{"ts":1361190229274,"patch":[[{"diffs":[[0,"                "],[1,"DataLogger.l(\"/tmp/wp_missing_ref_tpl.txt\", \"Missing: [[\" + title.text + \"]]\")"],[0,"\n            \n  "]],"start1":7611,"start2":7611,"length1":32,"length2":110}]],"length":8549,"saved":false}
{"ts":1361190239531,"patch":[[{"diffs":[[0,"p/wp_missing_ref"],[-1,"_tpl"],[0,".txt\", \"Missing:"]],"start1":7644,"start2":7644,"length1":36,"length2":32}]],"length":8545,"saved":false}
